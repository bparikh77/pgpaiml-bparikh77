{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "yMbLlraFPQli"
   },
   "outputs": [],
   "source": [
    "# import the necessary libraries\n",
    "import numpy as np\n",
    "from keras.datasets import imdb\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, LSTM, Embedding, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "69dtWj0Lf8Rz"
   },
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "max_len = 20\n",
    "embedding_size = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FY4CWeXOYvHb"
   },
   "source": [
    "# Import and split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "acSkLBkERjBw"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<__array_function__ internals>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "D:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\datasets\\imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "D:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\datasets\\imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T4z94ahgaDfp"
   },
   "source": [
    "# Analyze the data, print shape of features and labels, print value of any one feature and it's label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0fXP00oaZ_aU",
    "outputId": "ab6a59cb-16b0-4c3b-8703-deaf2a7b9bd4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Train data:\n",
      "(25000,)\n",
      "(25000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of Train data:\")\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NzPrqN7KbaU5",
    "outputId": "eb154c5a-89c5-43e4-d848-86fc9c5f10db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Test data:\n",
      "(25000,)\n",
      "(25000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of Test data:\")\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "eROKuJ-Jev5q"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 14,\n",
       " 22,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 973,\n",
       " 1622,\n",
       " 1385,\n",
       " 65,\n",
       " 458,\n",
       " 4468,\n",
       " 66,\n",
       " 3941,\n",
       " 4,\n",
       " 173,\n",
       " 36,\n",
       " 256,\n",
       " 5,\n",
       " 25,\n",
       " 100,\n",
       " 43,\n",
       " 838,\n",
       " 112,\n",
       " 50,\n",
       " 670,\n",
       " 2,\n",
       " 9,\n",
       " 35,\n",
       " 480,\n",
       " 284,\n",
       " 5,\n",
       " 150,\n",
       " 4,\n",
       " 172,\n",
       " 112,\n",
       " 167,\n",
       " 2,\n",
       " 336,\n",
       " 385,\n",
       " 39,\n",
       " 4,\n",
       " 172,\n",
       " 4536,\n",
       " 1111,\n",
       " 17,\n",
       " 546,\n",
       " 38,\n",
       " 13,\n",
       " 447,\n",
       " 4,\n",
       " 192,\n",
       " 50,\n",
       " 16,\n",
       " 6,\n",
       " 147,\n",
       " 2025,\n",
       " 19,\n",
       " 14,\n",
       " 22,\n",
       " 4,\n",
       " 1920,\n",
       " 4613,\n",
       " 469,\n",
       " 4,\n",
       " 22,\n",
       " 71,\n",
       " 87,\n",
       " 12,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 38,\n",
       " 76,\n",
       " 15,\n",
       " 13,\n",
       " 1247,\n",
       " 4,\n",
       " 22,\n",
       " 17,\n",
       " 515,\n",
       " 17,\n",
       " 12,\n",
       " 16,\n",
       " 626,\n",
       " 18,\n",
       " 2,\n",
       " 5,\n",
       " 62,\n",
       " 386,\n",
       " 12,\n",
       " 8,\n",
       " 316,\n",
       " 8,\n",
       " 106,\n",
       " 5,\n",
       " 4,\n",
       " 2223,\n",
       " 5244,\n",
       " 16,\n",
       " 480,\n",
       " 66,\n",
       " 3785,\n",
       " 33,\n",
       " 4,\n",
       " 130,\n",
       " 12,\n",
       " 16,\n",
       " 38,\n",
       " 619,\n",
       " 5,\n",
       " 25,\n",
       " 124,\n",
       " 51,\n",
       " 36,\n",
       " 135,\n",
       " 48,\n",
       " 25,\n",
       " 1415,\n",
       " 33,\n",
       " 6,\n",
       " 22,\n",
       " 12,\n",
       " 215,\n",
       " 28,\n",
       " 77,\n",
       " 52,\n",
       " 5,\n",
       " 14,\n",
       " 407,\n",
       " 16,\n",
       " 82,\n",
       " 2,\n",
       " 8,\n",
       " 4,\n",
       " 107,\n",
       " 117,\n",
       " 5952,\n",
       " 15,\n",
       " 256,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 3766,\n",
       " 5,\n",
       " 723,\n",
       " 36,\n",
       " 71,\n",
       " 43,\n",
       " 530,\n",
       " 476,\n",
       " 26,\n",
       " 400,\n",
       " 317,\n",
       " 46,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 1029,\n",
       " 13,\n",
       " 104,\n",
       " 88,\n",
       " 4,\n",
       " 381,\n",
       " 15,\n",
       " 297,\n",
       " 98,\n",
       " 32,\n",
       " 2071,\n",
       " 56,\n",
       " 26,\n",
       " 141,\n",
       " 6,\n",
       " 194,\n",
       " 7486,\n",
       " 18,\n",
       " 4,\n",
       " 226,\n",
       " 22,\n",
       " 21,\n",
       " 134,\n",
       " 476,\n",
       " 26,\n",
       " 480,\n",
       " 5,\n",
       " 144,\n",
       " 30,\n",
       " 5535,\n",
       " 18,\n",
       " 51,\n",
       " 36,\n",
       " 28,\n",
       " 224,\n",
       " 92,\n",
       " 25,\n",
       " 104,\n",
       " 4,\n",
       " 226,\n",
       " 65,\n",
       " 16,\n",
       " 38,\n",
       " 1334,\n",
       " 88,\n",
       " 12,\n",
       " 16,\n",
       " 283,\n",
       " 5,\n",
       " 16,\n",
       " 4472,\n",
       " 113,\n",
       " 103,\n",
       " 32,\n",
       " 15,\n",
       " 16,\n",
       " 5345,\n",
       " 19,\n",
       " 178,\n",
       " 32]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "viqCsvDGiklz",
    "outputId": "b5688d00-768a-4181-a498-d5aecd2058f3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decode the feature value to get original sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the word index dictionary\n",
    "\n",
    "word_index_dict = imdb.get_word_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the key value pairs of words and their indexes\n",
    "\n",
    "key_list = list(word_index_dict.keys())\n",
    "val_list = list(word_index_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the as you with out themselves powerful lets loves their becomes reaching had journalist of lot from anyone to have after out atmosphere never more room and it so heart shows to years of every never going and help moments or of every chest visual movie except her was several of enough more with is now current film as you of mine potentially unfortunately of you than him that with out themselves her get for was camp of you movie sometimes movie that with scary but and to story wonderful that in seeing in character to of 70s musicians with heart had shadows they of here that with her serious to have does when from why what have critics they is you that isn't one will very to as itself with other and in of seen over landed for anyone of and br show's to whether from than out themselves history he name half some br of and odd was two most of mean for 1 any an boat she he should is thought frog but of script you not while history he heart to real at barrel but when from one bit then have two of script their with her nobody most that with wasn't to with armed acting watch an for with heartfelt film want an\n"
     ]
    }
   ],
   "source": [
    "# Iterate through one of the moview review sequences in the training dataset and \n",
    "# extract the corresponding words based on their indexes in the imdb word index dictionary  \n",
    "\n",
    "text = \"\"\n",
    "j=0\n",
    "\n",
    "# Select the first movie sequence in the below case, i.e. X_train[0] and show its corresponding text\n",
    "\n",
    "for i in range (0,len(X_train[0])):\n",
    "    index = val_list.index(X_train[0][j])\n",
    "    word = key_list[index]\n",
    "    text = text + \" \" + word\n",
    "    j=j+1\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5seabQq_QQNQ"
   },
   "source": [
    "# Perform relevant sequence padding on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "Ry3s1NHWarbR"
   },
   "outputs": [],
   "source": [
    "X_train = tf.keras.preprocessing.sequence.pad_sequences(X_train, maxlen=max_len, padding='post')\n",
    "X_test = tf.keras.preprocessing.sequence.pad_sequences(X_test, maxlen=max_len, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b-1sqIAgQRVn"
   },
   "source": [
    "# Design, train, tune and test a sequential model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "5Eh29o8iQER5"
   },
   "outputs": [],
   "source": [
    "# create the model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size + 1, embedding_size, input_length=max_len))\n",
    "model.add(LSTM(128))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 20, 50)            500050    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 128)               91648     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 616,531\n",
      "Trainable params: 616,531\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "Bb1czkbafwrr"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "B_R5se5YftCj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "196/196 [==============================] - 30s 114ms/step - loss: 0.6138 - accuracy: 0.6345 - val_loss: 0.4825 - val_accuracy: 0.7604\n",
      "Epoch 2/20\n",
      "196/196 [==============================] - 22s 114ms/step - loss: 0.3997 - accuracy: 0.8223 - val_loss: 0.4901 - val_accuracy: 0.7579\n",
      "Epoch 3/20\n",
      "196/196 [==============================] - 21s 110ms/step - loss: 0.3249 - accuracy: 0.8609 - val_loss: 0.5232 - val_accuracy: 0.7589\n",
      "Epoch 4/20\n",
      "196/196 [==============================] - 23s 119ms/step - loss: 0.2511 - accuracy: 0.8928 - val_loss: 0.6463 - val_accuracy: 0.7454\n",
      "Epoch 5/20\n",
      "196/196 [==============================] - 23s 119ms/step - loss: 0.2012 - accuracy: 0.9110 - val_loss: 0.7313 - val_accuracy: 0.7367\n",
      "Epoch 6/20\n",
      "196/196 [==============================] - 24s 122ms/step - loss: 0.1564 - accuracy: 0.9321 - val_loss: 0.8296 - val_accuracy: 0.7298\n",
      "Epoch 7/20\n",
      "196/196 [==============================] - 24s 122ms/step - loss: 0.1262 - accuracy: 0.9483 - val_loss: 1.1942 - val_accuracy: 0.7242\n",
      "Epoch 8/20\n",
      "196/196 [==============================] - 24s 121ms/step - loss: 0.0892 - accuracy: 0.9630 - val_loss: 1.1659 - val_accuracy: 0.7170\n",
      "Epoch 9/20\n",
      "196/196 [==============================] - 25s 130ms/step - loss: 0.0748 - accuracy: 0.9701 - val_loss: 1.4151 - val_accuracy: 0.7255\n",
      "Epoch 10/20\n",
      "196/196 [==============================] - 25s 127ms/step - loss: 0.0573 - accuracy: 0.9787 - val_loss: 1.4638 - val_accuracy: 0.7194\n",
      "Epoch 11/20\n",
      "196/196 [==============================] - 23s 116ms/step - loss: 0.0455 - accuracy: 0.9835 - val_loss: 1.5349 - val_accuracy: 0.7207\n",
      "Epoch 12/20\n",
      "196/196 [==============================] - 22s 113ms/step - loss: 0.0369 - accuracy: 0.9866 - val_loss: 2.0918 - val_accuracy: 0.7236\n",
      "Epoch 13/20\n",
      "196/196 [==============================] - 21s 109ms/step - loss: 0.0270 - accuracy: 0.9905 - val_loss: 1.9035 - val_accuracy: 0.7308\n",
      "Epoch 14/20\n",
      "196/196 [==============================] - 24s 123ms/step - loss: 0.0259 - accuracy: 0.9912 - val_loss: 2.3006 - val_accuracy: 0.7184\n",
      "Epoch 15/20\n",
      "196/196 [==============================] - 25s 129ms/step - loss: 0.0249 - accuracy: 0.9910 - val_loss: 2.1206 - val_accuracy: 0.7160\n",
      "Epoch 16/20\n",
      "196/196 [==============================] - 22s 114ms/step - loss: 0.0166 - accuracy: 0.9938 - val_loss: 2.3477 - val_accuracy: 0.7269\n",
      "Epoch 17/20\n",
      "196/196 [==============================] - 19s 95ms/step - loss: 0.0207 - accuracy: 0.9934 - val_loss: 2.2123 - val_accuracy: 0.7175\n",
      "Epoch 18/20\n",
      "196/196 [==============================] - 20s 105ms/step - loss: 0.0128 - accuracy: 0.9962 - val_loss: 2.4629 - val_accuracy: 0.7237\n",
      "Epoch 19/20\n",
      "196/196 [==============================] - 18s 94ms/step - loss: 0.0101 - accuracy: 0.9964 - val_loss: 2.4823 - val_accuracy: 0.7236\n",
      "Epoch 20/20\n",
      "196/196 [==============================] - 19s 97ms/step - loss: 0.0142 - accuracy: 0.9958 - val_loss: 2.6049 - val_accuracy: 0.7223\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c0970a7400>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=20, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model is overfit as shown above with a training accuracy reaching almost 100%, but test accuracy not crossing 73%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use the designed model to print the prediction on any one sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the predictions into binary, i.e. 0 / True or 1 / False\n",
    "y_pred_binary = y_pred >= 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display any one prediction (false as shown below)\n",
    "y_pred_binary[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction is false as shown above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display any one prediction (true as shown below)\n",
    "y_pred_binary[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction is True as shown above"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "PGPAIML_R9_Project1_SeqentialNLP.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
