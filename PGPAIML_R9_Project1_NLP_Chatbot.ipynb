{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the JSON file with the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"GL Bot.json\") as file:\n",
    "    corpus = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an array of text and labels from the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "W=[] # text array\n",
    "L=[] # labels array\n",
    "doc_X=[]\n",
    "doc_Y=[]\n",
    "for intent in corpus[\"intents\"]:\n",
    "    for pattern in intent[\"patterns\"]:\n",
    "        w_temp = nltk.word_tokenize(pattern) # tokenize the text\n",
    "        W.extend(w_temp)\n",
    "        doc_X.append(w_temp)\n",
    "        doc_Y.append(intent[\"tag\"])\n",
    "    \n",
    "    if intent[\"tag\"] not in L:\n",
    "        L.append(intent[\"tag\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the train and target arrays with the one hot encoded numerical data to be processed by the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=[]\n",
    "target=[] \n",
    "\n",
    "out_empty = [0 for _ in range(len(L))]\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "for x, doc in enumerate(doc_X):\n",
    "    bag=[]\n",
    "    w_temp = [lemmatizer.lemmatize(w.lower()) for w in doc] # use lemmatization to reduce the words to their roots\n",
    "    for w in W:\n",
    "        if w in w_temp:\n",
    "            bag.append(1)\n",
    "        else:\n",
    "            bag.append(0)\n",
    "    \n",
    "    output_row = out_empty[:]\n",
    "    output_row[L.index(doc_Y[x])] = 1\n",
    "    \n",
    "    train.append(bag)\n",
    "    target.append(output_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import  train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, target, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use RandomForest model and fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfl = RandomForestClassifier(random_state=42)\n",
    "rfl.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9775280898876404"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Training Accuracy\")\n",
    "rfl.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4358974358974359"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Testing Accuracy\")\n",
    "rfl.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a function that takes text as input and convers it into the encoded text array to be fed into the model for label / response prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(inp_txt):\n",
    "    bag=[]\n",
    "    inp_words = nltk.word_tokenize(inp_txt)\n",
    "    w_temp = [lemmatizer.lemmatize(w.lower()) for w in inp_words]\n",
    "    for w in W:\n",
    "        if w in w_temp:\n",
    "            bag.append(1)\n",
    "        else:\n",
    "            bag.append(0)\n",
    "    return np.reshape(bag, (1,-1)) # convert the 1D array to 2D array, as expected by the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the chatbot function which will display the response after capturing the input from the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot():\n",
    "    global rfl\n",
    "    responses = ''\n",
    "    print(\"Welcome to my new Chatbot (type Quit to exit)\")\n",
    "    print(\"If response is not correct,type:*\")\n",
    "    while True:\n",
    "        inp = input(\" \")\n",
    "        if inp.lower() == \"*\":\n",
    "            print(\"BOT: Please rephrase your question and try again\")\n",
    "            break\n",
    "        if inp.lower() == \"quit\":\n",
    "            break\n",
    "        \n",
    "        result = rfl.predict(bag_of_words(inp)) # get the encoded result / label data\n",
    "        result_index = np.argmax(result) # get the index with the max value, i.e. 1 in this case\n",
    "        tag = L[result_index] # get the label / tag with the corresponding index from the label array\n",
    "        \n",
    "        for tg in corpus[\"intents\"]:\n",
    "            if tg['tag'] == tag:\n",
    "                responses = tg[\"responses\"] # capture the response for the index related to above label\n",
    "        print(responses) # show the response to the end user       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Invoke the chatbot function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to my new Chatbot (type Quit to exit)\n",
      "If response is not correct,type:*\n",
      " adam\n",
      "['Link: Neural Nets wiki']\n",
      " sgd\n",
      "['Link: Neural Nets wiki']\n",
      " joke\n",
      "['Hello! how can i help you ?']\n",
      " useless bot\n",
      "['Link: Machine Learning wiki ']\n",
      " Hello\n",
      "['Hello! how can i help you ?']\n",
      " How are you?\n",
      "['Hello! how can i help you ?']\n",
      " wow\n",
      "['Link: Machine Learning wiki ']\n",
      " great\n",
      "['Hello! how can i help you ?']\n",
      " blended\n",
      "['Link: Machine Learning wiki ']\n",
      " online\n",
      "['Hello! how can i help you ?']\n",
      " thanks\n",
      "['I hope I was able to assist you, Good Bye']\n",
      " ton\n",
      "['Link: Machine Learning wiki ']\n",
      " great help\n",
      "['I hope I was able to assist you, Good Bye']\n",
      " too good\n",
      "['I hope I was able to assist you, Good Bye']\n",
      " thanks a ton\n",
      "['I hope I was able to assist you, Good Bye']\n",
      " later\n",
      "['Link: Machine Learning wiki ']\n",
      " good bye\n",
      "['I hope I was able to assist you, Good Bye']\n",
      " see you\n",
      "['I hope I was able to assist you, Good Bye']\n",
      " see you later\n",
      "['I hope I was able to assist you, Good Bye']\n",
      " cya\n",
      "['I hope I was able to assist you, Good Bye']\n",
      " olympus\n",
      "['Link: Olympus wiki']\n",
      " teach\n",
      "['Link: Machine Learning wiki ']\n",
      " teach me\n",
      "['Hello! how can i help you ?']\n",
      " teach me olympus\n",
      "['Link: Olympus wiki']\n"
     ]
    }
   ],
   "source": [
    "chatbot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
